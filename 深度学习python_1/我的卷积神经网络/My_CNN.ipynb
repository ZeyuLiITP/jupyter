{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dca24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T06:15:47.799619Z",
     "start_time": "2024-04-06T06:15:47.786921Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a953400",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09da51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:24:48.469392Z",
     "start_time": "2024-04-06T08:24:48.134328Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir) #将父目录添加到默认搜寻目录\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.util import im2col,col2im\n",
    "import math \n",
    "from common.optimizer import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d3232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:23:42.424707Z",
     "start_time": "2024-04-06T08:23:42.415185Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.layers import Convolution,Pooling,Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8106ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:25:17.089826Z",
     "start_time": "2024-04-06T08:25:16.991014Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False,one_hot_label=True)\n",
    "#导入训练数据和测试数据\n",
    "x_train_1=x_train[:100]\n",
    "t_train_1=t_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e0dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:24:53.520994Z",
     "start_time": "2024-04-06T08:24:53.494440Z"
    },
    "code_folding": [
     0,
     10,
     22,
     64,
     102,
     119,
     144,
     148
    ]
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 溢出对策\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "class my_conv:\n",
    "    def __init__(self,W,b,stride=1, pad=0): \n",
    "        self.FN ,self.C ,self.FH, self.FW = W.shape\n",
    "        self.stride = stride;\n",
    "        self.pad = pad;\n",
    "        self.x = None;   \n",
    "        self.col = None;\n",
    "        self.col_W = None;\n",
    "        self.W = W\n",
    "        self.b = b #(FN,)\n",
    "        self.dW = None;\n",
    "        self.db = None;\n",
    "        \n",
    "    def forward(self,x):\n",
    "        N, C , H, W = x.shape;\n",
    "        OH = int( (H + 2*0 -self.FH)/1 + 1 );\n",
    "        OW = int( (W + 2*0 -self.FW)/1 + 1 );\n",
    "        \n",
    "        x_col = im2col(x,self.FH,self.FW ,stride=1,pad=0);\n",
    "        filter_flat = self.W.reshape(self.FN , -1).T;\n",
    "        \n",
    "        x_aftercov = np.dot(x_col,filter_flat) + self.b\n",
    "        x_aftercov = (x_aftercov.T.reshape(self.FN,N,OH,OW).transpose(1,0,2,3)) \n",
    "        \n",
    "        self.x = x\n",
    "        self.col = x_col\n",
    "        self.col_W = filter_flat\n",
    "        return x_aftercov\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "class my_pool:\n",
    "    def __init__(self,pool_h, pool_w ,stride = 1, pad = 0):\n",
    "        self.pool_h = pool_h;\n",
    "        self.pool_w = pool_w;\n",
    "        self.stride = stride;\n",
    "        self.pad = pad;\n",
    "        self.arg_max = None;\n",
    "        self.x = None;\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.x = x;\n",
    "        N, C , H, W = x.shape;\n",
    "        OH = int( (H + 2*self.pad -self.pool_h)/self.stride + 1 );\n",
    "        OW = int( (W + 2*self.pad -self.pool_w)/self.stride + 1 );\n",
    "        \n",
    "        x_col = im2col(x,self.pool_h,self.pool_w ,stride=self.stride,pad=0);\n",
    "        x_col = x_col.reshape(-1,self.pool_h*self.pool_w);\n",
    "        arg_max = np.argmax(x_col, axis=1);\n",
    "        self.arg_max = arg_max;\n",
    "                            \n",
    "        out = np.max(x_col,axis=1);\n",
    "        out = out.reshape(N,OH,OW,C).transpose(0,3,1,2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "class ReLu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "    \n",
    "class my_Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W;\n",
    "        self.b = b;\n",
    "        self.x = None;\n",
    "        self.original_x_shape = None;\n",
    "        self.dW = None;\n",
    "        self.db = None;   #这一层的权重和偏置的梯度数据会被保存下来\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.original_x_shape = x.shape;\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        self.x = x;\n",
    "        out = np.dot(self.x , self.W) + self.b;\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout,self.W.T);\n",
    "        self.dW = np.dot(self.x.T, dout);\n",
    "        dx = dx.reshape(*self.original_x_shape)  # 还原输入数据的形状（对应张量）\n",
    "        self.db = np.sum(dout,axis=0);\n",
    "        \n",
    "        return dx #将dx作为输出继续流向下一层\n",
    "    \n",
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmax的输出\n",
    "        self.t = None # 监督数据\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08020b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:24:55.011284Z",
     "start_time": "2024-04-06T08:24:55.007212Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def my_cross_entropy(x,t): #这里的t需要是One-hot形式\n",
    "    delta = 1e-7\n",
    "    batch_size = x.shape[0]\n",
    "    return -np.sum(np.log(x+delta) * t) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e6f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:24:59.924279Z",
     "start_time": "2024-04-06T08:24:59.918785Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class my_softmax_loss:\n",
    "    def __init__(self):\n",
    "        self.loss = None;\n",
    "        self.t = None;\n",
    "        self.y = None;\n",
    "        \n",
    "    def forward(self,x,t): #这里的t需要是One-hot形式\n",
    "        self.y = softmax(x);\n",
    "        self.t = t;\n",
    "        self.loss = my_cross_entropy(self.y , t);\n",
    "        return self.loss\n",
    "        \n",
    "        \n",
    "    def backward(self):\n",
    "        dout = 1;\n",
    "        batch_size= self.t.shape[0];\n",
    "        out = (self.y - self.t)/batch_size;\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09fe82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:25:01.923925Z",
     "start_time": "2024-04-06T08:25:01.918742Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class my_AdaGrad:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr;\n",
    "        self.h = None;\n",
    "        \n",
    "    def update(self,params,grads): #这里输入的params和grads要求是字典变量\n",
    "        if self.h == None:\n",
    "            self.h = {};\n",
    "            for keys,values in params.items():\n",
    "                self.h[keys] = np.zeros_like(values);\n",
    "                \n",
    "        else:\n",
    "            for keys in params.keys():\n",
    "                self.h[keys] += grads[keys]*grads[keys];\n",
    "                params[keys] -= self.lr * grads[keys] / (np.sqrt(self.h[keys]) + 1e-7)\n",
    "        #不需要返回值，输入的params在经过update运算后会发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c0ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:25:04.920793Z",
     "start_time": "2024-04-06T08:25:04.910724Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class my_cnn_network:\n",
    "    def __init__(self,input_dim=(1,28,28),conv_param={'filter_num': 20,'filter_size': 5,\"stride\":1,\"pad\":0},\n",
    "                 hidden_size=50,output_size=10,weitght_int_std=0.01):\n",
    "        \n",
    "        self.C,self.H,self.W = input_dim;\n",
    "        self.FN = conv_param['filter_num'];\n",
    "        self.FH = conv_param['filter_size'];\n",
    "        self.FW = conv_param['filter_size'];\n",
    "        stride = 1;\n",
    "        conv_output = int((self.H-self.FH)/stride + 1)\n",
    "        pool_output_size = int(self.FN * (conv_output/2) * (conv_output/2)) #池化后神经元个数\n",
    "        \n",
    "        self.params = {};\n",
    "        self.layers = OrderedDict();\n",
    "        \n",
    "        self.params['W1'] = np.sqrt(2.0/ (self.C*self.H*self.W)) * np.random.randn(self.FN,self.C,self.FH,self.FW);\n",
    "        self.params['b1'] =np.zeros(self.FN);\n",
    "        self.layers['conv'] = my_conv(self.params['W1'],self.params['b1'])\n",
    "        \n",
    "        self.layers['relu1'] = ReLu(); \n",
    "        self.layers['pool'] = my_pool(2,2,stride=2);\n",
    "        \n",
    "        self.params['W2'] = np.sqrt(2.0/pool_output_size)*np.random.randn(pool_output_size,hidden_size);\n",
    "        self.params['b2'] = np.zeros(hidden_size);\n",
    "        self.layers['affine1'] = my_Affine(self.params['W2'],self.params['b2']);\n",
    "        \n",
    "        self.layers['relu2'] = ReLu();\n",
    "        \n",
    "        self.params['W3'] = np.sqrt(2.0/hidden_size)*np.random.randn(hidden_size,output_size);\n",
    "        self.params['b3'] = np.zeros(output_size);\n",
    "        self.layers['affine2'] = my_Affine(self.params['W3'],self.params['b3']);\n",
    "        \n",
    "        self.last_layer = my_softmax_loss();\n",
    "        self.loss_value = None;\n",
    "        \n",
    "    def predict(self,x):\n",
    "        x_predict = x;\n",
    "        for layers in self.layers.values():\n",
    "            x_predict = layers.forward(x_predict)\n",
    "            \n",
    "        return x_predict\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        x_predict = self.predict(x);\n",
    "        loss = self.last_layer.forward(x_predict,t)\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        layers = list(self.layers.values());\n",
    "        layers.reverse();\n",
    "        \n",
    "        self.loss_value = self.loss(x,t);\n",
    "        \n",
    "        dout = self.last_layer.backward();\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout);\n",
    "            \n",
    "        grads={}\n",
    "        grads['W1'] = self.layers['conv'].dW\n",
    "        grads['b1'] = self.layers['conv'].db\n",
    "        grads['W2'] = self.layers['affine1'].dW\n",
    "        grads['b2'] = self.layers['affine1'].db\n",
    "        grads['W3'] = self.layers['affine2'].dW\n",
    "        grads['b3'] = self.layers['affine2'].db\n",
    "        \n",
    "        \n",
    "        \n",
    "        return grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c60466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:23:56.010193Z",
     "start_time": "2024-04-06T08:23:55.984068Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class my_cnn_network1:\n",
    "    def __init__(self,input_dim=(1,28,28),conv_param={'filter_num': 30,'filter_size': 5,\"stride\":1,\"pad\":0},\n",
    "                 hidden_size=100,output_size=10,weitght_int_std=0.01):\n",
    "        \n",
    "        self.C,self.H,self.W = input_dim;\n",
    "        self.FN = conv_param['filter_num'];\n",
    "        self.FH = conv_param['filter_size'];\n",
    "        self.FW = conv_param['filter_size'];\n",
    "        stride = 1;\n",
    "        conv_output = int((self.H-self.FH)/stride + 1)\n",
    "        pool_output_size = int(self.FN * (conv_output/2) * (conv_output/2)) #池化后神经元个数\n",
    "        \n",
    "        self.params = {};\n",
    "        self.layers = OrderedDict();\n",
    "        \n",
    "        self.params['W1'] = weitght_int_std * np.random.randn(self.FN,self.C,self.FH,self.FW);\n",
    "        self.params['b1'] =np.zeros(self.FN);\n",
    "        self.layers['conv'] = Convolution(self.params['W1'], self.params['b1'])\n",
    "        \n",
    "        self.layers['relu1'] = ReLu(); \n",
    "        self.layers['pool'] = Pooling(2,2,2);\n",
    "        \n",
    "        self.params['W2'] = weitght_int_std*np.random.randn(pool_output_size,hidden_size);\n",
    "        self.params['b2'] = np.zeros(hidden_size);\n",
    "        self.layers['affine1'] = my_Affine(self.params['W2'],self.params['b2']);\n",
    "        \n",
    "        self.layers['relu2'] = ReLu();\n",
    "        \n",
    "        self.params['W3'] = weitght_int_std*np.random.randn(hidden_size,output_size);\n",
    "        self.params['b3'] = np.zeros(output_size);\n",
    "        self.layers['affine2'] = my_Affine(self.params['W3'],self.params['b3']);\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss();\n",
    "        self.loss_value = None;\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        x_predict = self.predict(x);\n",
    "        loss = self.last_layer.forward(x_predict,t)\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        layers = list(self.layers.values());\n",
    "        layers.reverse();\n",
    "        \n",
    "        self.loss_value = self.loss(x,t);\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout);\n",
    "            \n",
    "        grads={}\n",
    "        grads['W1'] = self.layers['conv'].dW\n",
    "        grads['b1'] = self.layers['conv'].db\n",
    "        grads['W2'] = self.layers['affine1'].dW\n",
    "        grads['b2'] = self.layers['affine1'].db\n",
    "        grads['W3'] = self.layers['affine2'].dW\n",
    "        grads['b3'] = self.layers['affine2'].db\n",
    "        \n",
    "        \n",
    "        \n",
    "        return grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9f851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c01d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T06:15:48.519781Z",
     "start_time": "2024-04-06T06:15:48.504673Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1ce05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:26:24.416200Z",
     "start_time": "2024-04-06T08:26:24.406283Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "cnnnetwork = my_cnn_network();\n",
    "losslist=[]; #记录损失函数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b469d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:26:25.734911Z",
     "start_time": "2024-04-06T08:26:25.725916Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdaGrad(lr=0.001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04723f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T07:38:58.814786Z",
     "start_time": "2024-04-06T07:38:58.811351Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58f122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:13:06.039967Z",
     "start_time": "2024-04-06T08:13:06.035385Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = SGD();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57b595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:27:37.123878Z",
     "start_time": "2024-04-06T08:26:30.766262Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_mask = np.random.choice(60000,100);\n",
    "    x_train_batch = x_train[batch_mask];\n",
    "    t_train_batch = t_train[batch_mask];  #每一次学习都随机选300个数据\n",
    "    \n",
    "    grads = cnnnetwork.gradient(x_train_batch,t_train_batch);\n",
    "    losslist.append(cnnnetwork.loss_value);\n",
    "    optimizer.update(cnnnetwork.params,grads)\n",
    "    if i % 100 ==0 :\n",
    "        print(str(i) + '|' + str(losslist[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43b6c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:25:30.955917Z",
     "start_time": "2024-04-06T08:25:30.942854Z"
    }
   },
   "outputs": [],
   "source": [
    "begin = cnnnetwork.params['W3'][0]\n",
    "print(begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1322160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:40:45.133014Z",
     "start_time": "2024-04-06T08:40:45.123786Z"
    }
   },
   "outputs": [],
   "source": [
    "finish = cnnnetwork.params['W3'][0]\n",
    "print(finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5d741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:30:54.229307Z",
     "start_time": "2024-04-06T08:30:50.581043Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_result = np.argmax(cnnnetwork.predict(x_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b4bcc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:31:38.729847Z",
     "start_time": "2024-04-06T08:31:38.725980Z"
    }
   },
   "outputs": [],
   "source": [
    "true_result = np.argmax(t_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b6552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:34:50.613358Z",
     "start_time": "2024-04-06T08:34:50.603158Z"
    }
   },
   "outputs": [],
   "source": [
    "np.count_nonzero((true_result == predict_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f669a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:35:03.165121Z",
     "start_time": "2024-04-06T08:35:03.156710Z"
    }
   },
   "outputs": [],
   "source": [
    "9230 / len(true_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf31b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "27.994px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
